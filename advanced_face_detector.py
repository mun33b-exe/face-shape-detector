"""
Advanced CNN Face Shape Detector with GPU acceleration
Optimized for high accuracy using transfer learning and data augmentation
Designed for GTX 1660 Ti with 6GB VRAM and i5-9300H with 32GB RAM
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model, applications, optimizers, callbacks
from tensorflow.keras.mixed_precision import set_global_policy
import numpy as np
import cv2
import os
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Advanced GPU Configuration for GTX 1660 Ti
print("ï¿½ Advanced GPU Configuration for GTX 1660 Ti")
print(f"TensorFlow version: {tf.__version__}")

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        # Enable memory growth and configure for 6GB VRAM
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
            # Set memory limit to prevent OOM on 6GB card
            tf.config.experimental.set_memory_limit(gpu, 5120)  # 5GB limit for safety
        
        # Enable mixed precision for faster training on GTX 1660 Ti
        set_global_policy('mixed_float16')
        
        print(f"âœ… GPU Acceleration: {len(gpus)} GPU(s) detected")
        print(f"âš¡ Mixed Precision: Enabled (FP16)")
        print(f"ğŸ’¾ Memory Limit: 5GB (safe for 6GB VRAM)")
        
        for i, gpu in enumerate(gpus):
            print(f"   ğŸ® GPU {i}: {gpu.name}")
            
    except RuntimeError as e:
        print(f"âŒ GPU configuration error: {e}")
        print("ğŸ”„ Falling back to default GPU settings")
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
else:
    print("âš ï¸ No GPU detected - using CPU (training will be much slower)")

class AdvancedFaceShapeDetector:
    def __init__(self, dataset_path="FaceShape Dataset"):
        self.dataset_path = dataset_path
        self.model = None
        self.base_model = None
        self.label_encoder = LabelEncoder()
        self.img_size = (224, 224)  # Optimal for EfficientNet
        self.face_shapes = ['Heart', 'Oblong', 'Oval', 'Round', 'Square']
        self.batch_size = 16  # Optimized for GTX 1660 Ti 6GB VRAM
        self.model_name = None
        
        print(f"ğŸ¯ Advanced Face Shape Detector Initialized")
        print(f"ğŸ“Š Target Classes: {self.face_shapes}")
        print(f"ğŸ–¼ï¸ Image Size: {self.img_size}")
        print(f"ğŸ›ï¸ Batch Size: {self.batch_size} (optimized for GTX 1660 Ti)")
        
    def load_and_preprocess_data(self, validation_split=0.2):
        """Load and preprocess the face shape dataset with advanced techniques"""
        print("ğŸ“Š Loading and preprocessing data...")
        
        images = []
        labels = []
        
        # Count total images first for progress tracking
        total_images = 0
        train_dir = os.path.join(self.dataset_path, 'training_set')
        for shape in self.face_shapes:
            shape_dir = os.path.join(train_dir, shape)
            if os.path.exists(shape_dir):
                shape_images = [f for f in os.listdir(shape_dir) 
                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                total_images += len(shape_images)
        
        print(f"ğŸ“ˆ Total images to process: {total_images}")
        
        # Load training data with progress tracking
        processed = 0
        for shape in self.face_shapes:
            shape_dir = os.path.join(train_dir, shape)
            if os.path.exists(shape_dir):
                print(f"ğŸ“ Processing {shape} images...")
                shape_count = 0
                for img_file in os.listdir(shape_dir):
                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        img_path = os.path.join(shape_dir, img_file)
                        try:
                            # Load and preprocess image with quality checks
                            img = cv2.imread(img_path)
                            if img is not None and img.shape[0] > 32 and img.shape[1] > 32:
                                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                                img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_LANCZOS4)
                                
                                # Quality check - reject very dark or very bright images
                                img_mean = np.mean(img)
                                if 20 < img_mean < 235:  # Good brightness range
                                    img = img.astype(np.float32) / 255.0  # Normalize to [0,1]
                                    
                                    images.append(img)
                                    labels.append(shape)
                                    shape_count += 1
                                    processed += 1
                                    
                                    if processed % 500 == 0:
                                        print(f"   ğŸ“¸ Processed {processed}/{total_images} images...")
                                        
                        except Exception as e:
                            print(f"âš ï¸ Error loading {img_path}: {e}")
                            continue
                print(f"âœ… {shape}: {shape_count} high-quality images loaded")
        
        # Convert to numpy arrays with memory optimization
        X = np.array(images, dtype=np.float32)
        y = np.array(labels)
        
        # Encode labels
        y_encoded = self.label_encoder.fit_transform(y)
        
        print(f"ğŸ¯ Dataset loaded successfully!")
        print(f"   ğŸ“Š Total images: {len(X)}")
        print(f"   ğŸ–¼ï¸ Image shape: {X.shape}")
        print(f"   ğŸ·ï¸ Classes: {dict(zip(*np.unique(y, return_counts=True)))}")
        print(f"   ğŸ’¾ Memory usage: {X.nbytes / (1024**2):.1f} MB")
        
        return X, y_encoded
    
    def create_advanced_model(self, num_classes=5):
        """Create state-of-the-art CNN model optimized for GTX 1660 Ti"""
        print("ğŸ—ï¸ Building advanced CNN model with transfer learning...")
        
        # Use EfficientNetB0 as base model (optimal for GTX 1660 Ti)
        base_model = applications.EfficientNetB0(
            weights='imagenet',
            include_top=False,
            input_shape=(*self.img_size, 3),
            drop_connect_rate=0.2
        )
        
        # Initially freeze the base model
        base_model.trainable = False
        
        # Create custom head for face shape classification
        inputs = keras.Input(shape=(*self.img_size, 3))
        
        # Data augmentation layer (applied during training)
        x = layers.RandomFlip("horizontal")(inputs)
        x = layers.RandomRotation(0.1)(x)
        x = layers.RandomZoom(0.1)(x)
        x = layers.RandomContrast(0.1)(x)
        x = layers.RandomBrightness(0.1)(x)
        
        # Base model
        x = base_model(x, training=False)
        
        # Custom classification head
        x = layers.GlobalAveragePooling2D()(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.3)(x)
        
        # Dense layers with progressive reduction
        x = layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.5)(x)
        
        x = layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.4)(x)
        
        x = layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.3)(x)
        
        # Output layer with float32 for numerical stability
        outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
        
        # Create model
        model = keras.Model(inputs, outputs)
        
        # Advanced optimizer with learning rate scheduling
        initial_learning_rate = 0.001
        lr_schedule = keras.optimizers.schedules.ExponentialDecay(
            initial_learning_rate,
            decay_steps=1000,
            decay_rate=0.96,
            staircase=True
        )
        
        # Compile with advanced settings
        model.compile(
            optimizer=optimizers.Adam(learning_rate=lr_schedule, epsilon=1e-8),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', 'top_2_accuracy']
        )
        
        self.model = model
        self.base_model = base_model
        
        print("âœ… Advanced model created successfully!")
        print(f"   ğŸ§  Total parameters: {model.count_params():,}")
        print(f"   ğŸ”’ Trainable parameters: {sum([tf.keras.utils.count_params(w) for w in model.trainable_weights]):,}")
        print(f"   ğŸ“‹ Base model: EfficientNetB0 (ImageNet pretrained)")
        print(f"   ğŸ¯ Custom head: Progressive dense layers with regularization")
        print(f"   ğŸ¨ Data augmentation: Integrated into model")        
        return model
    
    def get_advanced_callbacks(self, model_name='advanced_face_shape_model'):
        """Setup comprehensive training callbacks optimized for GTX 1660 Ti"""
        callbacks_list = [
            # Early stopping with patience for longer training
            callbacks.EarlyStopping(
                monitor='val_accuracy',
                patience=20,
                restore_best_weights=True,
                verbose=1,
                min_delta=0.001
            ),
            
            # Aggressive learning rate reduction
            callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-8,
                verbose=1,
                cooldown=3
            ),
            
            # Model checkpointing with validation accuracy
            callbacks.ModelCheckpoint(
                f'{model_name}.h5',
                monitor='val_accuracy',
                save_best_only=True,
                save_weights_only=False,
                verbose=1,
                mode='max'
            ),
            
            # TensorBoard for training visualization
            callbacks.TensorBoard(
                log_dir=f'logs/{model_name}_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
                histogram_freq=1,
                write_graph=True,
                write_images=False,  # Disable to save VRAM
                update_freq='epoch'
            ),
            
            # CSV logging for analysis
            callbacks.CSVLogger(f'{model_name}_training.csv', append=True),
        ]
        
        return callbacks_list
    
    def train_model(self, X, y, epochs=100, validation_split=0.2):
        """Advanced two-stage training optimized for high accuracy"""
        print("ğŸš€ Starting advanced two-stage training process...")
        print(f"ğŸ“Š Training configuration:")
        print(f"   ğŸ”„ Total epochs: {epochs}")
        print(f"   ğŸ“¦ Batch size: {self.batch_size}")
        print(f"   ğŸ“Š Validation split: {validation_split}")
        print(f"   ğŸ¯ Expected accuracy improvement: 35% â†’ 85-95%")
        
        # Split data with stratification
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=validation_split, 
            random_state=42, stratify=y
        )
        
        print(f"ğŸ“ˆ Data split:")
        print(f"   ğŸ“ Training: {len(X_train)} images")
        print(f"   âœ… Validation: {len(X_val)} images")
        
        # Stage 1: Train with frozen base model (transfer learning)
        print("\nğŸ¯ Stage 1: Transfer Learning (Frozen Base Model)")
        print("=" * 60)
        
        stage1_epochs = min(30, epochs // 3)
        stage1_callbacks = self.get_advanced_callbacks('stage1_model')
        
        history_stage1 = self.model.fit(
            X_train, y_train,
            batch_size=self.batch_size,
            epochs=stage1_epochs,
            validation_data=(X_val, y_val),
            callbacks=stage1_callbacks,
            verbose=1,
            shuffle=True
        )
        
        # Stage 2: Fine-tuning with unfrozen base model
        if epochs > 30:
            print("\nğŸ”¥ Stage 2: Fine-tuning (Unfrozen Base Model)")
            print("=" * 60)
            
            # Unfreeze the base model for fine-tuning
            self.base_model.trainable = True
            
            # Use a much lower learning rate for fine-tuning
            fine_tune_lr = 0.0001
            self.model.compile(
                optimizer=optimizers.Adam(learning_rate=fine_tune_lr),
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy', 'top_2_accuracy']
            )
            
            print(f"ğŸ”§ Base model unfrozen: {len(self.base_model.layers)} layers")
            print(f"ğŸ“‰ Fine-tuning learning rate: {fine_tune_lr}")
            
            stage2_epochs = epochs - stage1_epochs
            stage2_callbacks = self.get_advanced_callbacks('final_advanced_model')
            
            history_stage2 = self.model.fit(
                X_train, y_train,
                batch_size=self.batch_size,
                epochs=stage2_epochs,
                validation_data=(X_val, y_val),
                callbacks=stage2_callbacks,
                verbose=1,
                shuffle=True
            )
            
            # Combine training histories
            history = self.combine_histories(history_stage1, history_stage2)
        else:
            history = history_stage1
        
        print("\nâœ… Advanced training completed successfully!")
        return history
    
    def combine_histories(self, hist1, hist2):
        """Combine training histories from two stages"""
        combined = {}
        for key in hist1.history.keys():
            combined[key] = hist1.history[key] + hist2.history[key]
        
        # Create a simple object to hold the combined history
        class CombinedHistory:
            def __init__(self, history_dict):
                self.history = history_dict
        
        return CombinedHistory(combined)
        self.model_name = "EfficientNet"
        
        return model
    
    def create_resnet_model(self):
        """Create ResNet50V2-based model as alternative"""
        print("ğŸ—ï¸ Creating ResNet50V2-based model...")
        
        # Load pre-trained ResNet50V2
        base_model = ResNet50V2(
            input_shape=(*self.img_size, 3),
            include_top=False,
            weights='imagenet'
        )
        
        # Freeze base model initially
        base_model.trainable = False
        
        # Add custom head
        inputs = keras.Input(shape=(*self.img_size, 3))
        x = base_model(inputs, training=False)
        x = layers.GlobalAveragePooling2D()(x)
        x = layers.Dropout(0.3)(x)
        x = layers.Dense(1024, activation='relu')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.4)(x)
        x = layers.Dense(512, activation='relu')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.5)(x)
        outputs = layers.Dense(len(self.face_shapes), activation='softmax')(x)
        
        model = Model(inputs, outputs)
        self.model_name = "ResNet50V2"
        
        return model
    
    def create_custom_cnn_model(self):
        """Create custom CNN optimized for face shapes"""
        print("ğŸ—ï¸ Creating custom CNN model...")
        
        model = keras.Sequential([
            # First Block
            layers.Conv2D(64, (3, 3), activation='relu', input_shape=(*self.img_size, 3)),
            layers.BatchNormalization(),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D(2, 2),
            layers.Dropout(0.25),
            
            # Second Block
            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.MaxPooling2D(2, 2),
            layers.Dropout(0.25),
            
            # Third Block
            layers.Conv2D(256, (3, 3), activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2D(256, (3, 3), activation='relu'),
            layers.MaxPooling2D(2, 2),
            layers.Dropout(0.25),
            
            # Fourth Block
            layers.Conv2D(512, (3, 3), activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2D(512, (3, 3), activation='relu'),
            layers.MaxPooling2D(2, 2),
            layers.Dropout(0.25),
            
            # Dense layers
            layers.GlobalAveragePooling2D(),
            layers.Dense(1024, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(512, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(len(self.face_shapes), activation='softmax')
        ])
        
        self.model_name = "CustomCNN"
        return model
    
    def get_advanced_data_augmentation(self):
        """Get advanced data augmentation for better generalization"""
        return keras.preprocessing.image.ImageDataGenerator(
            rotation_range=15,
            width_shift_range=0.15,
            height_shift_range=0.15,
            horizontal_flip=True,
            zoom_range=0.15,
            shear_range=0.1,
            brightness_range=[0.8, 1.2],
            channel_shift_range=0.1,
            fill_mode='nearest'
        )
    
    def train_model(self, X_train, X_val, y_train, y_val, model_type='efficient', epochs=100):
        """Train the model with advanced techniques"""
        print(f"ğŸš€ Training {model_type} model...")
        
        # Create model based on type
        if model_type == 'efficient':
            self.model = self.create_efficient_model()
        elif model_type == 'resnet':
            self.model = self.create_resnet_model()
        else:
            self.model = self.create_custom_cnn_model()
        
        # Compile model
        initial_learning_rate = 0.001
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=initial_learning_rate),
            loss='categorical_crossentropy',
            metrics=['accuracy', 'top_2_accuracy']
        )
        
        print(f"ğŸ“Š Model summary:")
        print(f"Total parameters: {self.model.count_params():,}")
        
        # Callbacks
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_accuracy',
                patience=15,
                restore_best_weights=True,
                verbose=1
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=8,
                min_lr=1e-7,
                verbose=1
            ),
            keras.callbacks.ModelCheckpoint(
                f'best_{model_type}_face_shape_model.h5',
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            ),
            keras.callbacks.CSVLogger(
                f'{model_type}_training_log.csv'
            )
        ]
        
        # Data augmentation
        train_datagen = self.get_advanced_data_augmentation()
        val_datagen = keras.preprocessing.image.ImageDataGenerator()  # No augmentation for validation
        
        # Calculate steps
        steps_per_epoch = len(X_train) // self.batch_size
        validation_steps = len(X_val) // self.batch_size
        
        print(f"ğŸ”„ Training configuration:")
        print(f"   Batch size: {self.batch_size}")
        print(f"   Steps per epoch: {steps_per_epoch}")
        print(f"   Validation steps: {validation_steps}")
        print(f"   Max epochs: {epochs}")
        
        # Phase 1: Train with frozen base (for transfer learning models)
        if model_type in ['efficient', 'resnet']:
            print("ğŸ“š Phase 1: Training with frozen base model...")
            history1 = self.model.fit(
                train_datagen.flow(X_train, y_train, batch_size=self.batch_size),
                steps_per_epoch=steps_per_epoch,
                epochs=min(20, epochs//3),
                validation_data=val_datagen.flow(X_val, y_val, batch_size=self.batch_size),
                validation_steps=validation_steps,
                callbacks=callbacks,
                verbose=1
            )
            
            # Phase 2: Fine-tune with unfrozen layers
            print("ğŸ”“ Phase 2: Fine-tuning with unfrozen layers...")
            base_model = self.model.layers[1]  # Get base model
            base_model.trainable = True
            
            # Freeze early layers, unfreeze later layers
            freeze_layers = len(base_model.layers) // 2
            for layer in base_model.layers[:freeze_layers]:
                layer.trainable = False
            
            # Lower learning rate for fine-tuning
            self.model.compile(
                optimizer=keras.optimizers.Adam(learning_rate=initial_learning_rate/10),
                loss='categorical_crossentropy',
                metrics=['accuracy', 'top_2_accuracy']
            )
            
            # Continue training
            history2 = self.model.fit(
                train_datagen.flow(X_train, y_train, batch_size=self.batch_size),
                steps_per_epoch=steps_per_epoch,
                epochs=epochs - min(20, epochs//3),
                validation_data=val_datagen.flow(X_val, y_val, batch_size=self.batch_size),
                validation_steps=validation_steps,
                callbacks=callbacks,
                verbose=1,
                initial_epoch=min(20, epochs//3)
            )
            
            # Combine histories
            history = self._combine_histories(history1, history2)
        else:
            # Train custom CNN normally
            history = self.model.fit(
                train_datagen.flow(X_train, y_train, batch_size=self.batch_size),
                steps_per_epoch=steps_per_epoch,
                epochs=epochs,
                validation_data=val_datagen.flow(X_val, y_val, batch_size=self.batch_size),
                validation_steps=validation_steps,
                callbacks=callbacks,
                verbose=1
            )
        
        return history
    
    def _combine_histories(self, hist1, hist2):
        """Combine two training histories"""
        combined = {}
        for key in hist1.history.keys():
            combined[key] = hist1.history[key] + hist2.history[key]
        
        class CombinedHistory:
            def __init__(self, history_dict):
                self.history = history_dict
        
        return CombinedHistory(combined)
    
    def evaluate_model(self):
        """Comprehensive model evaluation with detailed metrics"""
        print("ğŸ“Š Evaluating model on test set...")
        
        # Load test data
        test_images = []
        test_labels = []
        
        test_dir = os.path.join(self.dataset_path, 'testing_set')
        total_test_images = 0
        
        for shape in self.face_shapes:
            shape_dir = os.path.join(test_dir, shape)
            if os.path.exists(shape_dir):
                shape_count = 0
                for img_file in os.listdir(shape_dir):
                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        img_path = os.path.join(shape_dir, img_file)
                        try:
                            img = cv2.imread(img_path)
                            if img is not None:
                                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                                img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_LANCZOS4)
                                img = img.astype(np.float32) / 255.0
                                
                                test_images.append(img)
                                test_labels.append(shape)
                                shape_count += 1
                                
                        except Exception as e:
                            print(f"Error loading test image {img_path}: {e}")
                
                print(f"âœ… Test {shape}: {shape_count} images loaded")
                total_test_images += shape_count
        
        if not test_images:
            print("âš ï¸ No test images found")
            return 0.0
        
        X_test = np.array(test_images, dtype=np.float32)
        y_test_encoded = self.label_encoder.transform(test_labels)
        
        print(f"ğŸ“Š Test set: {len(X_test)} images")
        
        # Evaluate model
        test_results = self.model.evaluate(X_test, y_test_encoded, verbose=0)
        test_loss, test_accuracy, test_top2_accuracy = test_results
        
        # Get predictions for detailed analysis
        print("ğŸ” Generating predictions for detailed analysis...")
        y_pred = self.model.predict(X_test, batch_size=self.batch_size, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        # Classification report
        print("\nğŸ“‹ Detailed Classification Report:")
        print("=" * 60)
        report = classification_report(
            y_test_encoded, y_pred_classes,
            target_names=self.face_shapes,
            digits=4,
            output_dict=True
        )
        
        # Print formatted report
        for shape in self.face_shapes:
            if shape in report:
                metrics = report[shape]
                print(f"{shape:>10}: Precision={metrics['precision']:.4f}, "
                      f"Recall={metrics['recall']:.4f}, F1={metrics['f1-score']:.4f}")
        
        # Overall metrics
        print(f"\nğŸ¯ Overall Performance:")
        print(f"   ğŸ“Š Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
        print(f"   ğŸ¥ˆ Top-2 Accuracy: {test_top2_accuracy:.4f} ({test_top2_accuracy*100:.2f}%)")
        print(f"   ğŸ“‰ Test Loss: {test_loss:.4f}")
        print(f"   ğŸ“ˆ Macro Avg F1: {report['macro avg']['f1-score']:.4f}")
        print(f"   âš–ï¸ Weighted Avg F1: {report['weighted avg']['f1-score']:.4f}")
        
        # Confusion matrix
        cm = confusion_matrix(y_test_encoded, y_pred_classes)
        self.plot_confusion_matrix(cm, self.face_shapes)
        
        # Per-class accuracy
        print(f"\nğŸ“Š Per-class Accuracy:")
        for i, shape in enumerate(self.face_shapes):
            class_mask = y_test_encoded == i
            class_acc = np.mean(y_pred_classes[class_mask] == y_test_encoded[class_mask])
            print(f"   {shape:>10}: {class_acc:.4f} ({class_acc*100:.2f}%)")
        
        return test_accuracy
    
    def plot_confusion_matrix(self, cm, class_names):
        """Create and save confusion matrix visualization"""
        plt.figure(figsize=(12, 10))
        
        # Create heatmap with annotations
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names,
                   cbar_kws={'label': 'Number of Predictions'})
        
        plt.title('Confusion Matrix - Advanced Face Shape Detection', fontsize=16, fontweight='bold')
        plt.ylabel('True Label', fontsize=14)
        plt.xlabel('Predicted Label', fontsize=14)
        
        # Add accuracy percentages
        total = np.sum(cm)
        accuracy_text = f'Overall Accuracy: {np.trace(cm) / total:.2%}'
        plt.figtext(0.02, 0.02, accuracy_text, fontsize=12, bbox=dict(boxstyle="round", facecolor='wheat'))
        
        plt.tight_layout()
        plt.savefig('advanced_confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("ğŸ“Š Confusion matrix saved as 'advanced_confusion_matrix.png'")
    
    def predict_face_shape(self, image, return_probabilities=False):
        """Predict face shape with advanced preprocessing and confidence scores"""
        if isinstance(image, str):
            # Load image from path
            img = cv2.imread(image)
            if img is not None:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            else:
                raise ValueError("Could not load image")
        else:
            img = image.copy()
        
        # Advanced preprocessing
        img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_LANCZOS4)
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, axis=0)
        
        # Predict
        predictions = self.model.predict(img, verbose=0)
        predicted_class = np.argmax(predictions[0])
        confidence = predictions[0][predicted_class]
        
        face_shape = self.label_encoder.inverse_transform([predicted_class])[0]
        
        if return_probabilities:
            # Return all class probabilities
            all_probs = {}
            for i, shape in enumerate(self.face_shapes):
                all_probs[shape] = float(predictions[0][i])
            return face_shape, float(confidence), all_probs
        
        return face_shape, float(confidence)
    
    def save_model(self, filepath='advanced_face_shape_model.h5'):
        """Save the trained model with comprehensive metadata"""
        # Save the model
        self.model.save(filepath)
        
        # Create comprehensive metadata
        metadata = {
            'model_info': {
                'type': 'Advanced CNN with EfficientNetB0',
                'framework': 'TensorFlow/Keras',
                'version': tf.__version__,
                'created_date': datetime.now().isoformat(),
                'optimizer': 'Adam with learning rate scheduling',
                'architecture': 'EfficientNetB0 + Custom Head'
            },
            'dataset_info': {
                'face_shapes': self.face_shapes,
                'num_classes': len(self.face_shapes),
                'img_size': self.img_size,
                'preprocessing': 'Normalized to [0,1], Quality filtered'
            },
            'training_info': {
                'batch_size': self.batch_size,
                'two_stage_training': True,
                'data_augmentation': 'Integrated in model',
                'regularization': 'L2, Dropout, BatchNorm'
            },
            'hardware_optimized': {
                'gpu': 'NVIDIA GTX 1660 Ti (6GB VRAM)',
                'cpu': 'Intel i5-9300H',
                'ram': '32GB',
                'mixed_precision': True
            },
            'label_encoder_classes': self.label_encoder.classes_.tolist()
        }
        
        # Save metadata
        metadata_path = filepath.replace('.h5', '_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"ğŸ’¾ Advanced model saved to {filepath}")
        print(f"ğŸ“„ Metadata saved to {metadata_path}")
        print(f"ğŸ“Š Model size: {os.path.getsize(filepath) / (1024**2):.1f} MB")
    
    def load_model(self, filepath='advanced_face_shape_model.h5'):
        """Load a pre-trained advanced model with metadata"""
        try:
            # Load model
            self.model = keras.models.load_model(filepath)
            
            # Load metadata if available
            metadata_path = filepath.replace('.h5', '_metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                
                # Restore configuration
                self.face_shapes = metadata['dataset_info']['face_shapes']
                self.img_size = tuple(metadata['dataset_info']['img_size'])
                self.label_encoder.classes_ = np.array(metadata['label_encoder_classes'])
                
                print(f"âœ… Advanced model loaded from {filepath}")
                print(f"ğŸ“Š Model type: {metadata['model_info']['type']}")
                print(f"ğŸ¯ Classes: {self.face_shapes}")
                print(f"ğŸ“… Created: {metadata['model_info']['created_date']}")
            else:
                print(f"âœ… Model loaded from {filepath} (no metadata found)")
            
            return True
            
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            return False
    
    def plot_training_history(self, history, save_path='training_history.png'):
        """Plot comprehensive training history"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Accuracy plots
        axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)
        axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
        axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # Loss plots
        axes[0, 1].plot(history.history['loss'], label='Training Loss', linewidth=2)
        axes[0, 1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
        axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # Top-2 accuracy if available
        if 'top_2_accuracy' in history.history:
            axes[1, 0].plot(history.history['top_2_accuracy'], label='Training Top-2 Acc', linewidth=2)
            axes[1, 0].plot(history.history['val_top_2_accuracy'], label='Validation Top-2 Acc', linewidth=2)
            axes[1, 0].set_title('Top-2 Accuracy', fontsize=14, fontweight='bold')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Top-2 Accuracy')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        
        # Learning rate if available
        if 'lr' in history.history:
            axes[1, 1].plot(history.history['lr'], linewidth=2, color='red')
            axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Learning Rate')
            axes[1, 1].set_yscale('log')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')        plt.close()
        print(f"ğŸ“Š Training history saved as '{save_path}'")

if __name__ == "__main__":
    print("ğŸ­ Advanced Face Shape Detector - Deep Learning Edition")
    print("=" * 70)
    print("ğŸš€ Optimized for GTX 1660 Ti with 6GB VRAM and i5-9300H with 32GB RAM")
    print("ğŸ¯ Expected accuracy improvement: 35% â†’ 85-95%")
    print()
    
    # Check GPU status
    if tf.config.list_physical_devices('GPU'):
        print("âœ… GPU acceleration enabled - training will be fast!")
    else:
        print("âš ï¸ No GPU detected - training will be much slower")
        print("ğŸ’¡ Consider installing CUDA and cuDNN for GPU acceleration")
    
    print("\nğŸ“Š Starting advanced model training...")
    
    # Initialize detector
    detector = AdvancedFaceShapeDetector("FaceShape Dataset")
    
    # Load and preprocess data
    print("\nğŸ“Š Loading and preprocessing dataset...")
    X, y = detector.load_and_preprocess_data()
    
    # Create advanced model
    print("\nğŸ—ï¸ Creating advanced CNN model...")
    model = detector.create_advanced_model()
    
    # Display model architecture
    print("\nğŸ“‹ Model Architecture Summary:")
    model.summary()
    
    # Train model with advanced techniques
    print("\nğŸš€ Starting advanced training (this may take 30-60 minutes)...")
    print("ğŸ’¡ Training progress will be displayed below.")
    print("ğŸ“Š TensorBoard logs will be saved for detailed analysis.")
    
    try:
        history = detector.train_model(X, y, epochs=80)
        
        # Plot training history
        detector.plot_training_history(history)
        
        # Comprehensive evaluation
        print("\nğŸ“Š Comprehensive model evaluation...")
        accuracy = detector.evaluate_model()
        
        # Save model
        print("\nğŸ’¾ Saving advanced model...")
        detector.save_model()
        
        # Final results
        print("\n" + "="*70)
        print("ğŸ‰ ADVANCED TRAINING COMPLETED SUCCESSFULLY! ğŸ‰")
        print("="*70)
        print(f"ğŸ“Š Final Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"ğŸ¯ Accuracy Improvement: ~{((accuracy - 0.35) / 0.35 * 100):+.1f}% vs lightweight model")
        print(f"ğŸ’¾ Model saved as: advanced_face_shape_model.h5")
        print(f"ğŸ“Š Training history: training_history.png")
        print(f"ğŸ“‹ Confusion matrix: advanced_confusion_matrix.png")
        print(f"ğŸ“„ Metadata: advanced_face_shape_model_metadata.json")
        print()
        print("ğŸš€ Ready for high-accuracy face shape detection!")
        print("ğŸ’¡ Use the model with camera_detector.py or streamlit_app.py")
        
    except Exception as e:
        print(f"\nâŒ Training failed with error: {e}")
        print("ğŸ’¡ Try reducing batch_size if you encounter memory issues")
        print("ğŸ’¡ Ensure your dataset is properly organized and accessible")
        raise
    
    def predict_face_shape(self, image):
        """Predict face shape with confidence scores"""
        if isinstance(image, str):
            # Load image from path
            img = cv2.imread(image)
            if img is not None:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            else:
                raise ValueError("Could not load image")
        else:
            img = image
        
        # Preprocess
        img = cv2.resize(img, self.img_size)
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, axis=0)
        
        # Predict
        predictions = self.model.predict(img, verbose=0)
        predicted_class = np.argmax(predictions[0])
        confidence = predictions[0][predicted_class]
        
        # Get all predictions for detailed analysis
        all_predictions = {}
        for i, shape in enumerate(self.face_shapes):
            all_predictions[shape] = predictions[0][i]
        
        face_shape = self.label_encoder.inverse_transform([predicted_class])[0]
        
        return face_shape, confidence, all_predictions
    
    def save_model(self, filepath=None):
        """Save the trained model with metadata"""
        if filepath is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filepath = f'advanced_face_shape_model_{self.model_name.lower()}_{timestamp}.h5'
        
        self.model.save(filepath)
        
        # Save metadata
        metadata = {
            'model_name': self.model_name,
            'face_shapes': self.face_shapes,
            'img_size': self.img_size,
            'batch_size': self.batch_size,
            'timestamp': datetime.now().isoformat()
        }
        
        metadata_path = filepath.replace('.h5', '_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"ğŸ’¾ Model saved to: {filepath}")
        print(f"ğŸ“„ Metadata saved to: {metadata_path}")
    
    def load_model(self, filepath):
        """Load a pre-trained model"""
        try:
            self.model = keras.models.load_model(filepath)
            
            # Try to load metadata
            metadata_path = filepath.replace('.h5', '_metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                self.model_name = metadata.get('model_name', 'Unknown')
                self.face_shapes = metadata.get('face_shapes', self.face_shapes)
                self.img_size = tuple(metadata.get('img_size', self.img_size))
            
            print(f"âœ… Model loaded from: {filepath}")
            return True
        except Exception as e:
            print(f"âŒ Error loading model: {e}")
            return False

def main():
    """Main training function"""
    print("ğŸ­ Advanced Face Shape Detection with Deep Learning")
    print("=" * 60)
    
    # Initialize detector
    detector = AdvancedFaceShapeDetector("FaceShape Dataset")
    
    # Load and preprocess data
    print("ğŸ“Š Loading dataset...")
    X_train, X_val, y_train, y_val = detector.load_and_preprocess_data()
    
    # Choose model type
    print("\nğŸ¤– Available model types:")
    print("1. EfficientNet (Recommended - Best accuracy)")
    print("2. ResNet50V2 (Good accuracy, faster training)")
    print("3. Custom CNN (Fast training, moderate accuracy)")
    
    choice = input("\nChoose model type (1-3) [1]: ").strip() or "1"
    
    model_types = {'1': 'efficient', '2': 'resnet', '3': 'custom'}
    model_type = model_types.get(choice, 'efficient')
    
    # Training epochs
    epochs_input = input(f"\nEnter number of epochs [80]: ").strip() or "80"
    epochs = int(epochs_input)
    
    print(f"\nğŸš€ Starting training with {model_type} model for {epochs} epochs...")
    print("This may take 30-90 minutes depending on your GPU...")
    
    # Train model
    history = detector.train_model(X_train, X_val, y_train, y_val, model_type, epochs)
    
    # Plot training history
    detector.plot_training_history(history)
    
    # Evaluate model
    final_accuracy = detector.evaluate_model()
    
    # Save model
    detector.save_model()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Training completed successfully!")
    print(f"ğŸ“Š Final test accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)")
    print(f"ğŸš€ Expected accuracy improvement: ~60-90% (vs 35% baseline)")
    print("ğŸ’¾ Model and training logs saved")
    print("ğŸ¯ You can now use this model for high-accuracy face shape detection!")

if __name__ == "__main__":
    main()
